{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import cv2\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Target Folder : subject_id/synth/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시 데이터 제외하여 파일 또는 폴더 경로의 목록 반환 함수\n",
    "def get_filepath_list(path):\n",
    "    tmp_list = os.listdir(path)\n",
    "    real_list = []\n",
    "    for i in range(len(tmp_list)):\n",
    "        ut = tmp_list[i]\n",
    "        if ut[0] != \".\": # 임시파일 예제 : .00000.bmp\n",
    "            real_list.append(os.path.join(path,ut))\n",
    "    return real_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Root Path\n",
    "ut_path = \"./UTMultiview\"\n",
    "\n",
    "# Subject Group Path List\n",
    "ut_list = get_filepath_list(ut_path)\n",
    "\n",
    "# UT Multi View Data 폴더에서 각 Subject의 그룹 별 폴도 목록 출력\n",
    "print(ut_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pose(vector: np.ndarray) -> np.ndarray:\n",
    "    rot = cv2.Rodrigues(np.array(vector).astype(np.float32))[0]\n",
    "    vec = rot[:, 2]\n",
    "    pitch = np.arcsin(vec[1])\n",
    "    yaw = np.arctan2(vec[0], vec[2])\n",
    "    return np.array([pitch, yaw]).astype(np.float32)\n",
    "\n",
    "\n",
    "def convert_gaze(vector: np.ndarray) -> np.ndarray:\n",
    "    x, y, z = vector\n",
    "    pitch = np.arcsin(-y)\n",
    "    yaw = np.arctan2(-x, -z)\n",
    "    return np.array([pitch, yaw]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(path, zip_list):\n",
    "    # zip 파일 압축 해제 및 경로 리스트에 저장\n",
    "    unzip_list = []\n",
    "    for z_idx in range(len(zip_list)):\n",
    "        zip_file = zip_list[z_idx]\n",
    "        if zip_file[0] != \".\":\n",
    "            zip_nm = zip_file.replace(\"\\\\\",\"/\").split(\"/\")[-1].split(\".\")[0]\n",
    "            unzip_path = os.path.join(path, zip_nm)\n",
    "            if os.path.isdir(unzip_path) != True:\n",
    "                zip = zipfile.ZipFile(zip_file)\n",
    "                zip.extractall(path=unzip_path)\n",
    "            \n",
    "            unzip_list.append(unzip_path)\n",
    "    return unzip_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get UTM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ut_df(trg):\n",
    "    # 데이터프레임으로 구성하고자 하는 데이터의 리스트\n",
    "    datas = []\n",
    "\n",
    "    # Subject Group for문\n",
    "    for g_idx in tqdm(range(len(ut_list))):\n",
    "        group_path = ut_list[g_idx] # Subject Group Path\n",
    "\n",
    "        # Subject ID별 데이터 관리\n",
    "        sj_list = get_filepath_list(group_path)\n",
    "        for s_idx in range(len(sj_list)):\n",
    "            subject_path = sj_list[s_idx] # Subject ID별 경로\n",
    "            trg_path = os.path.join(subject_path, trg) # 사용할 데이터 폴더\n",
    "            # test_path = os.path.join(subject_path, \"test\") # 사용할 데이터 폴더\n",
    "            \n",
    "            csv_list = sorted(glob(os.path.join(trg_path, \"*.csv\"))) # csv 파일 리스트\n",
    "            zip_list = sorted(glob(os.path.join(trg_path, \"*.zip\"))) # zip 파일 리스트\n",
    "            \n",
    "            # zip 파일 압축 해제 및 경로 리스트에 저장\n",
    "            unzip_list = unzip_file(trg_path, zip_list)\n",
    "\n",
    "            # 압축이 해제 되어진 폴더 경로\n",
    "            for u_idx in range(len(unzip_list)):\n",
    "                unzip = unzip_list[u_idx].replace(\"\\\\\",\"/\")\n",
    "                \n",
    "                group_id = unzip.split(\"/\")[-4]\n",
    "                subject_id = unzip.split(\"/\")[-3] # Subject ID (s00, s01, ..., n)\n",
    "                seq_id = unzip.split(\"/\")[-1].split(\"_\")[0] # Sequence Number(0000, 0001, ... , n)\n",
    "                loc_id = unzip.split(\"/\")[-1].split(\"_\")[1] # Eye Location(Left or Right)\n",
    "                \n",
    "                img_list = get_filepath_list(unzip) # Image File List\n",
    "                pose_file = trg_path = os.path.join(ut_path, group_id, subject_id, \"raw\", \"img\"+str(seq_id), \"headpose.txt\")  # 사용할 데이터 폴더\n",
    "                with open(pose_file, 'r') as file:\n",
    "                    data = file.read()\n",
    "                # 데이터에서 HeadPose 부분 찾기\n",
    "                start = data.find(\"HeadPose\")\n",
    "                end = data.find(\"Features\")\n",
    "\n",
    "                # HeadPose 부분 추출\n",
    "                headpose_data = data[start:end]\n",
    "                headpose_lines = headpose_data.split('\\n')\n",
    "                \n",
    "                translation_line = headpose_lines[1].strip('[] ')  # 대괄호 및 공백 제거\n",
    "                translation = [float(x) for x in translation_line.split()]\n",
    "                translation_vector = np.array(translation)\n",
    "                \n",
    "                rotation_data = []\n",
    "                for l_idx in range(2,5):\n",
    "                    rotation_line = headpose_lines[l_idx].strip('[] ')\n",
    "                    rotation = [float(x) for x in rotation_line.split()]\n",
    "                    rotation_data.append(rotation)\n",
    "                rotation_matrix = np.array(rotation_data)\n",
    "                \n",
    "                # 트랜스레이션 벡터를 3D 위치 벡터로 변환\n",
    "                head_position = -translation_vector  # 위치 벡터는 -트랜스레이션 벡터\n",
    "\n",
    "                # 회전 행렬을 사용하여 방향 벡터 계산\n",
    "                direction_vector = np.array([0, 0, 1])  # 초기 방향 벡터 (예를 들어, 머리가 z-축 방향을 향할 때)\n",
    "\n",
    "                # 회전 행렬을 방향 벡터에 적용\n",
    "                direction_vector = np.array(direction_vector, dtype=float)\n",
    "                direction_vector_rotated = np.dot(rotation_matrix, direction_vector)\n",
    "\n",
    "                # 위치 벡터와 방향 벡터를 더하여 유닛 벡터 계산\n",
    "                head_direction = direction_vector_rotated + head_position\n",
    "\n",
    "                # 유닛 벡터로 정규화\n",
    "                head_unit_vector = head_direction / np.linalg.norm(head_direction)\n",
    "\n",
    "                pose_x, pose_y, pose_z = map(float, head_unit_vector)\n",
    "                pose_data = [pose_x,pose_y,pose_z]\n",
    "                if loc_id == \"left\":\n",
    "                    pose = convert_pose(pose_data)\n",
    "                else:\n",
    "                    pose = convert_pose(pose_data) * np.array([1, -1])\n",
    "                        \n",
    "                # Gaze CSV Data\n",
    "                columns = [\"gaze_x\", \"gaze_y\", \"gaze_z\"]\n",
    "                gaze_data = pd.read_csv(csv_list[u_idx], header=None).iloc[:,:3] # 0~8의 컬럼만 필요하기 때문에 마지막의 None 값의 컬럼은 제외\n",
    "                gaze_data.columns = columns\n",
    "                try:\n",
    "                    # gaze data의 행에 해당하는 이미지 호출하여 데이터프레임 구성\n",
    "                    for g_idx in range(len(gaze_data)):\n",
    "                        img_path = img_list[g_idx]\n",
    "                        image = cv2.imread(img_path)\n",
    "                        image_array = np.array(image)\n",
    "                        image_data_gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
    "                        \n",
    "                        gaze_data = [pose_x,pose_y,pose_z]\n",
    "                        \n",
    "                        if loc_id == \"left\":\n",
    "                            gaze = convert_gaze(gaze_data)\n",
    "                            image = image_data_gray\n",
    "                        else:\n",
    "                            image = image_data_gray[:, ::-1]\n",
    "                            gaze = convert_gaze(gaze_data) * np.array([1, -1])\n",
    "                            \n",
    "                        data_list = [subject_id, seq_id, loc_id, image.ravel(), pose[0], pose[1], gaze[0], gaze[1]]\n",
    "                        datas.append(data_list)\n",
    "                except:\n",
    "                    print(f\"ZIP ERROR : {subject_id} / {seq_id} / {loc_id}\\n\")\n",
    "\n",
    "    # 리스트에 담아두었던 정보들을 DataFrame으로 생성\n",
    "    data_df = pd.DataFrame(columns=[\"participant_id\",\"day\",\"eye_location\",\"image\",\"head_pitch\",\"head_yaw\",\"gaze_pitch\",\"gaze_yaw\"], data=datas)\n",
    "    data_df = data_df.sort_values(by=['participant_id', 'day']).reset_index(drop=True)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_df = get_ut_df(\"synth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = get_ut_df(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(data_df):\n",
    "    # 각 참가자의 위치와 이미지의 순서 별로 1500장씩 추출\n",
    "    desired_sequence_count = 1500\n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    for participant_id in sorted(data_df['participant_id'].unique()):\n",
    "        for eye_location in data_df['eye_location'].unique():\n",
    "            subset = data_df[(data_df['participant_id'] == participant_id) & (data_df['eye_location'] == eye_location)]\n",
    "            \n",
    "            if len(subset) >= desired_sequence_count:\n",
    "                sampled_subset = subset.sample(desired_sequence_count)\n",
    "            else:\n",
    "                sampled_subset = subset.sample(desired_sequence_count, replace=True)\n",
    "            \n",
    "            result_df = pd.concat([result_df, sampled_subset])\n",
    "    result_df.reset_index(drop=True,inplace=True)\n",
    "    return result_df\n",
    "\n",
    "sp_synth_df = sampling(synth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_id_list = sorted(list(set(list(synth_df[\"participant_id\"].values))))\n",
    "par_id_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ut_fold_maker(par_list):\n",
    "    train_id1 = copy.deepcopy(par_list)\n",
    "    train_id2 = copy.deepcopy(par_list)\n",
    "    train_id3 = copy.deepcopy(par_list)\n",
    "    test_id_list = copy.deepcopy(par_list)\n",
    "    \n",
    "    test_id1 = random.sample(test_id_list, 17)\n",
    "    for item in test_id1:\n",
    "        train_id1.remove(item)\n",
    "        test_id_list.remove(item)\n",
    "        \n",
    "    test_id2 = random.sample(test_id_list, 17)\n",
    "    for item in test_id2:\n",
    "        train_id2.remove(item)\n",
    "        test_id_list.remove(item)\n",
    "    \n",
    "    test_id3 = test_id_list\n",
    "    for item in test_id3:\n",
    "        train_id3.remove(item)\n",
    "    additional_rm_id = random.sample(train_id3, 1)\n",
    "    train_id3.remove(additional_rm_id[0])\n",
    "    \n",
    "    train_ids = [train_id1, train_id2, train_id3]\n",
    "    test_ids = [test_id1, test_id2, test_id3]\n",
    "    \n",
    "    return train_ids, test_ids\n",
    "\n",
    "train_ids, test_ids = ut_fold_maker(par_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy(data_df):\n",
    "    id_vector = np.asarray(data_df[\"participant_id\"].to_list())[np.newaxis,:]\n",
    "    images = np.stack(data_df[\"image\"].to_list()).reshape(-1,36,60)[np.newaxis,:]\n",
    "    hps = np.asarray(data_df[[\"head_pitch\", \"head_yaw\"]])[np.newaxis,:]\n",
    "    gazes = np.asarray(data_df[[\"gaze_pitch\", \"gaze_yaw\"]])[np.newaxis,:]\n",
    "    \n",
    "    return id_vector, images, hps, gazes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./utm_dataset/\"\n",
    "\n",
    "for i in range(3):\n",
    "    train_df = sp_synth_df[sp_synth_df[\"participant_id\"].isin(train_ids[i])]\n",
    "    test_df = real_df[real_df[\"participant_id\"].isin(test_ids[i])]\n",
    "    \n",
    "    tr_idv, tr_imgs, tr_hps, tr_gazes = get_numpy(train_df)\n",
    "    te_idv, te_imgs, te_hps, te_gazes = get_numpy(test_df)\n",
    "    \n",
    "    fold_path = os.path.join(save_path, \"loocv\", f\"Fold_{i+1}\")\n",
    "    if os.path.isdir(fold_path) != True:\n",
    "        os.makedirs(fold_path)\n",
    "    \n",
    "    np.save(os.path.join(fold_path, f\"utm_fold_{i+1}_train_ids\"), tr_idv)\n",
    "    np.save(os.path.join(fold_path, f\"utm_fold_{i+1}_test_ids\"), te_idv)\n",
    "    np.save(os.path.join(fold_path, f\"utm_fold_{i+1}_train_images\"), tr_imgs)\n",
    "    np.save(os.path.join(fold_path, f\"utm_fold_{i+1}_test_images\"), te_imgs)\n",
    "    np.save(os.path.join(fold_path, f\"utm_fold_{i+1}_train_2d_hps\"), tr_hps)\n",
    "    np.save(os.path.join(fold_path, f\"utm_fold_{i+1}_test_2d_hps\"), te_hps)\n",
    "    np.save(os.path.join(fold_path, f\"utm_fold_{i+1}_train_2d_gazes\"), tr_gazes)\n",
    "    np.save(os.path.join(fold_path, f\"utm_fold_{i+1}_test_2d_gazes\"), te_gazes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Within\n",
    "- Train : 각 참가자 별 이미지 2500장\n",
    "- Test : 각 참가자 별 이미지 500장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./utm_dataset/\"\n",
    "\n",
    "wtr_id_vector  = np.empty((10, 125000), dtype=object)\n",
    "wtr_images = np.empty((10, 125000, 36, 60))\n",
    "wtr_hps = np.empty((10, 125000, 2))\n",
    "wtr_gazes = np.empty((10, 125000, 2))\n",
    "\n",
    "wte_id_vector  = np.empty((10, 25000), dtype=object)\n",
    "wte_images = np.empty((10, 25000, 36, 60))\n",
    "wte_hps = np.empty((10, 25000, 2))\n",
    "wte_gazes = np.empty((10, 25000, 2))\n",
    "\n",
    "for i in range(10):\n",
    "    ttr_id_vector = np.empty((1, 0))\n",
    "    ttr_images = np.empty((1, 0, 36, 60))\n",
    "    ttr_hps = np.empty((1, 0, 2))\n",
    "    ttr_gazes = np.empty((1, 0, 2))\n",
    "    \n",
    "    tte_id_vector = np.empty((1, 0))\n",
    "    tte_images = np.empty((1, 0, 36, 60))\n",
    "    tte_hps = np.empty((1, 0, 2))\n",
    "    tte_gazes = np.empty((1, 0, 2))\n",
    "    \n",
    "    for par_idx in range(len(par_id_list)):\n",
    "        synth_par_df = sp_synth_df[sp_synth_df[\"participant_id\"] == par_id_list[par_idx]]\n",
    "        real_par_df = real_df[real_df[\"participant_id\"] == par_id_list[par_idx]]\n",
    "    \n",
    "        tr_idv, tr_imgs, tr_hps, tr_gazes = get_numpy(synth_par_df)\n",
    "        te_idv, te_imgs, te_hps, te_gazes = get_numpy(real_par_df)\n",
    "        \n",
    "        tr_random_indices = np.random.choice(tr_idv.shape[1], size=2500, replace=False)\n",
    "        te_random_indices = np.random.choice(te_idv.shape[1], size=500, replace=False)\n",
    "\n",
    "        str_id_vector = tr_idv[:, tr_random_indices]\n",
    "        str_images = tr_imgs[:, tr_random_indices]\n",
    "        str_hps = tr_hps[:, tr_random_indices]\n",
    "        str_gazes = tr_gazes[:, tr_random_indices]\n",
    "        \n",
    "        ste_id_vector = te_idv[:, te_random_indices]\n",
    "        ste_images = te_imgs[:, te_random_indices]\n",
    "        ste_hps = te_hps[:, te_random_indices]\n",
    "        ste_gazes = te_gazes[:, te_random_indices]\n",
    "        \n",
    "        ttr_id_vector = np.concatenate((ttr_id_vector, str_id_vector), axis=1)\n",
    "        ttr_images = np.concatenate((ttr_images, str_images), axis=1)\n",
    "        ttr_hps = np.concatenate((ttr_hps, str_hps), axis=1)\n",
    "        ttr_gazes = np.concatenate((ttr_gazes, str_gazes), axis=1)\n",
    "        \n",
    "        tte_id_vector = np.concatenate((tte_id_vector, ste_id_vector), axis=1)\n",
    "        tte_images = np.concatenate((tte_images, ste_images), axis=1)\n",
    "        tte_hps = np.concatenate((tte_hps, ste_hps), axis=1)\n",
    "        tte_gazes = np.concatenate((tte_gazes, ste_gazes), axis=1)\n",
    "    \n",
    "    wtr_id_vector[i, :] = ttr_id_vector\n",
    "    wtr_images[i, :, :, :] = ttr_images\n",
    "    wtr_hps[i, :, :] = ttr_hps    \n",
    "    wtr_gazes[i, :, :] = ttr_gazes\n",
    "    \n",
    "    wte_id_vector[i, :] = tte_id_vector\n",
    "    wte_images[i, :, :, :] = tte_images\n",
    "    wte_hps[i, :, :] = tte_hps    \n",
    "    wte_gazes[i, :, :] = tte_gazes\n",
    "    \n",
    "fold_path = os.path.join(save_path, \"within\")\n",
    "if os.path.isdir(fold_path) != True:\n",
    "    os.makedirs(fold_path)\n",
    "\n",
    "np.save(os.path.join(fold_path, f\"utm_within_train_ids\"), wtr_id_vector)\n",
    "np.save(os.path.join(fold_path, f\"utm_within_test_ids\"), wte_id_vector)\n",
    "np.save(os.path.join(fold_path, f\"utm_within_train_images\"), wtr_images)\n",
    "np.save(os.path.join(fold_path, f\"utm_within_test_images\"), wte_images)\n",
    "np.save(os.path.join(fold_path, f\"utm_within_train_2d_hps\"), wtr_hps)\n",
    "np.save(os.path.join(fold_path, f\"utm_within_test_2d_hps\"), wte_hps)\n",
    "np.save(os.path.join(fold_path, f\"utm_within_train_2d_gazes\"), wtr_gazes)\n",
    "np.save(os.path.join(fold_path, f\"utm_within_test_2d_gazes\"), wte_gazes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtr_gazes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wte_gazes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
